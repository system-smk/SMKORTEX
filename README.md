## ğŸ“˜ README â€” SMKortex : Assistant IA local en franÃ§ais + Interface WebUI

---

### ğŸ¤– PrÃ©sentation

SMKortex est un assistant IA **100â€¯% local**, conÃ§u pour fonctionner sans connexion internet aprÃ¨s installation. Il utilise `llama.cpp` associÃ© au modÃ¨le **Vigogne 2 7B**, optimisÃ© pour la conversation en franÃ§ais.

ğŸ’¡ Il propose deux modes dâ€™interaction :
- Terminal classique (`smkortex`)
- Interface Web interactive (`WebUI`) avec champ texte, bulles et animation cosmique

---

### ğŸ› ï¸ PrÃ©requis

- Linux ou macOS avec Bash
- Git, Make, wget et Node.js installÃ©s
- ~4 Go dâ€™espace libre pour le modÃ¨le
- Navigateur moderne pour la WebUI

---

### ğŸš€ Installation complÃ¨te

#### âœ… Ã‰tape 1 â€” Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/ton-utilisateur/smkortex.git
cd smkortex
```

#### âœ… Ã‰tape 2 â€” Lancer le script principal

```bash
bash main-smkortex.sh
```

Ce script installe automatiquement :

| Ã‰tape | Script appelÃ©                         | Action rÃ©alisÃ©e                                          |
|-------|----------------------------------------|----------------------------------------------------------|
| 1ï¸âƒ£   | `install-dependances.sh`               | Installe les paquets nÃ©cessaires                         |
| 2ï¸âƒ£   | `clone-compile-llama.sh`               | Clone `llama.cpp` et compile `llama-cli`                |
| 3ï¸âƒ£   | `telecharger-modele.sh`                | TÃ©lÃ©charge Vigogne `.gguf` dans `llama/models/`         |
| 4ï¸âƒ£   | `instChatv2-kortex.sh`                 | Configure lâ€™agent IA Shell local                        |
| 5ï¸âƒ£   | `configurer-lanceur.sh`                | CrÃ©e le raccourci terminal `smkortex`                   |
| 6ï¸âƒ£   | `install-smkortex-webui.sh`            | CrÃ©e lâ€™interface WebUI dans `webui/`                    |
| 7ï¸âƒ£   | `configurer-lanceur-webui.sh`          | CrÃ©e le raccourci terminal `webkortex`                  |
| ğŸ§¹   | *(option)* `desinstaller-smkortex.sh`   | Supprime proprement tout le projet                     |

---

### ğŸ’¬ Utilisation en ligne de commande

#### ğŸ”¹ MÃ©thode 1 â€” raccourci terminal

```bash
smkortex "Quel est le sens de la vie ?"
```

#### ğŸ”¹ MÃ©thode 2 â€” lancer le script directement

```bash
bash scripts/instChatv2-kortex.sh
```

> Les rÃ©ponses s'affichent en direct, et chaque session est loguÃ©e dans `logs/`.

---

### ğŸŒ Utilisation via Interface WebUI

#### ğŸ”¹ DÃ©marrer le serveur Web :

```bash
webkortex
```

> Lance le serveur Ã  l'adresse : [http://localhost:3000](http://localhost:3000)

#### ğŸ”¹ Interface 

- Champ texte pour poser tes questions
- Bouton **â€œParler Ã  Kortexâ€**

---

### ğŸ§± Arborescence finale attendue

```
SMKORTEX/
â”œâ”€â”€ main-smkortex.sh
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ instChatv2-kortex.sh
â”‚   â””â”€â”€ install-smkortex-webui.sh
â”œâ”€â”€ llama/
â”‚   â””â”€â”€ llama.cpp/
â”‚   â””â”€â”€ models/
â”œâ”€â”€ webui/
â”‚   â”œâ”€â”€ server.js
â”‚   â””â”€â”€ public/
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ style.css
â”‚       â””â”€â”€ app.js
â”œâ”€â”€ logs/
â””â”€â”€ README.md
```

---

### ğŸ§  ProblÃ¨mes frÃ©quents

| Message d'erreur                          | Cause probable                      | Solution recommandÃ©e              |
|------------------------------------------|-------------------------------------|-----------------------------------|
| `llama-cli: command not found`           | Binaire non compilÃ©                 | Relancer `clone-compile-llama.sh` |
| `model not found`                        | ModÃ¨le absent ou incorrect          | VÃ©rifier `llama/models/`          |
| `tee: logs/...log: Aucun fichier...`     | Dossier `logs/` manquant            | CrÃ©er avec `mkdir -p logs`        |
| WebUI rÃ©pond mais nâ€™affiche rien         | Script ne renvoie rien              | VÃ©rifier `echo` dans le script IA |
| `node: command not found`                | Node.js manquant                    | Installer avec `apt install nodejs npm` |

---

### ğŸ§¹ DÃ©sinstallation

```bash
bash scripts/desinstaller-smkortex.sh
```

---

### ğŸ§  Attribution et citation du modÃ¨le

SMKORTEX repose sur le modÃ¨le **Vigogne** :

> Huang, B. (2023). *Vigogne: French Instruction-following and Chat Models*  
> [GitHub repository](https://github.com/bofenghuang/vigogne)

```bibtex
@misc{vigogne,
  author       = {Bofeng Huang},
  title        = {Vigogne: French Instruction-following and Chat Models},
  year         = {2023},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/bofenghuang/vigogne}},
}
```
> "SMKORTEX powered by Vigogne ğŸ§  â€” modÃ¨le conversationnel franÃ§ais par @bofenghuang"

---

### ğŸ’š Auteur

Projet pensÃ©, organisÃ© et pilotÃ© par **Mathieu-Karim**,  
assistÃ© par Copilot âœ¨  

