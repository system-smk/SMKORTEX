## ğŸ“˜ README â€” SMKortex : Assistant IA local en franÃ§ais

---

### ğŸ¤– PrÃ©sentation

SMKortex est un assistant IA **100â€¯% local** en franÃ§ais, basÃ© sur `llama.cpp` et le modÃ¨le **Vigogne 2 7B**, conÃ§u pour fonctionner sans connexion internet aprÃ¨s installation.

Il propose un setup **modulaire et automatisÃ©**, avec des scripts organisÃ©s, une installation propre, et un raccourci terminal pour interagir facilement via `smkortex`.

---

### ğŸ› ï¸ PrÃ©requis

Avant de commencer :

- Linux ou macOS avec Bash
- Git, Make et wget installÃ©s
- CPU correct (ou GPU si intÃ©grÃ© dans le futur)
- ~4 Go dâ€™espace libre pour le modÃ¨le

---

### ğŸš€ Installation complÃ¨te

#### âœ… Ã‰tape 1 â€” Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/ton-utilisateur/smkortex.git
cd smkortex
```

#### âœ… Ã‰tape 2 â€” Lancer le script principal

```bash
bash main-smkortex.sh
```

Ce script exÃ©cute les Ã©tapes suivantes dans cet ordre :

| Ã‰tape | Script appelÃ©                  | Action rÃ©alisÃ©e                                      |
|-------|--------------------------------|------------------------------------------------------|
| 1ï¸âƒ£   | `install-dependances.sh`       | Installe les paquets nÃ©cessaires                     |
| 2ï¸âƒ£   | `clone-compile-llama.sh`       | Clone `llama.cpp` et compile `llama-cli`            |
| 3ï¸âƒ£   | `telecharger-modele.sh`        | TÃ©lÃ©charge Vigogne `.gguf` dans `llama/models/`     |
| 4ï¸âƒ£   | `installer-chatv2.sh`          | Installe `instChatv2-kortex.sh` dans `scripts/`     |
| 5ï¸âƒ£   | `configurer-lanceur.sh`        | CrÃ©e le raccourci global `smkortex`                 |
| 6ï¸âƒ£   | *(option)* `desinstaller-smkortex.sh` | Supprime tout proprement si choisi         |

---

### ğŸ§± Structure attendue aprÃ¨s installation

```
SMKORTEX/
â”œâ”€â”€ main-smkortex.sh
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ instChatv2-kortex.sh
â”œâ”€â”€ llama/
â”‚   â”œâ”€â”€ llama.cpp/
â”‚   â”‚   â””â”€â”€ build/bin/llama-cli
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ vigogne-2-7b-chat.Q4_K_M.gguf
â”œâ”€â”€ logs/         â† sessions interactives ici
â”œâ”€â”€ config/       â† paramÃ¨tres si nÃ©cessaires
â””â”€â”€ README.md
```

---

### ğŸ’¬ Lancement de lâ€™assistant IA

Deux mÃ©thodes pour dÃ©marrer une session :

#### ğŸ”¹ MÃ©thode 1 â€” via le raccourci

```bash
smkortex "Bonjour toi"
```

#### ğŸ”¹ MÃ©thode 2 â€” en lanÃ§ant directement le script

```bash
bash scripts/instChatv2-kortex.sh
```

> Chaque session gÃ©nÃ¨re un log dans `logs/` avec horodatage complet.

---

### ğŸ§  ProblÃ¨mes frÃ©quents

| Message d'erreur                          | Cause probable                         | Solution recommandÃ©e              |
|------------------------------------------|----------------------------------------|-----------------------------------|
| `llama-cli: command not found`           | Binaire non compilÃ©                    | Relance `clone-compile-llama.sh`  |
| `model not found`                        | ModÃ¨le absent ou chemin incorrect      | VÃ©rifie dans `llama/models/`      |
| `tee: logs/...log: Aucun fichier...`     | Dossier `logs/` manquant               | CrÃ©e avec `mkdir -p logs`         |
| ModÃ¨le fait quelques Ko seulement        | TÃ©lÃ©chargement incomplet               | Relance `telecharger-modele.sh`   |

---

### ğŸ“¦ DÃ©sinstallation

Si tu veux tout nettoyer proprement :

```bash
bash scripts/desinstaller-smkortex.sh
```

---

### ğŸ“š CrÃ©dits & citation du modÃ¨le

SMKortex repose sur le modÃ¨le **Vigogne**, dÃ©veloppÃ© pour lâ€™instruction et la conversation en franÃ§ais.  
Si vous utilisez ce projet dans un cadre acadÃ©mique ou technique, veuillez citer leurs travaux comme suit :

> Huang, B. (2023). *Vigogne: French Instruction-following and Chat Models* [GitHub repository]. GitHub. https://github.com/bofenghuang/vigogne

Ou en BibTeX :

```bibtex
@misc{vigogne,
  author       = {Bofeng Huang},
  title        = {Vigogne: French Instruction-following and Chat Models},
  year         = {2023},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  howpublished = {\url{https://github.com/bofenghuang/vigogne}},
}
```

---

### ğŸ’š Auteur

Projet pilotÃ© avec passion par **Mathieu-Karim** & son Copilote local ğŸ¦™  
Un assistant IA local, libre, hors cloud, et fier de parler franÃ§ais ğŸ‡«ğŸ‡·âœ¨

---

Tu veux aussi que je tâ€™ajoute un `CREDITS.md` sÃ©parÃ© ou que je lie cette citation au nom du modÃ¨le dans les logs ? Je peux aussi intÃ©grer Ã§a dans lâ€™intro interactive en mode :  
> "SMKortex powered by Vigogne ğŸ§  â€” modÃ¨le conversationnel franÃ§ais par @bofenghuang"

Tu me dis et je lâ€™injecte !
