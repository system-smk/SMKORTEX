
---

# 🗺️ `roadmap.md` — *Feuille de route de progression*

```markdown
# 📍 Feuille de Route – Agent IA Local

Dernière mise à jour : [DATE]

## 🎯 Objectif global

Construire un assistant IA local autonome, modulaire, vocal (optionnel), interconnecté à des outils personnalisés.

---

## ✅ Étape 1 – Setup initial

- [x] Générer l’arborescence du projet via `init.sh`
- [x] Remplir `config.json` (chemins, ports, options vocales)

---

## 🧠 Étape 2 – IA locale avec llama.cpp

- [ ] Télécharger modèle `.gguf` (TinyLlama ou Phi)
- [ ] Lancer modèle en local (`./main`)
- [ ] Écrire un script Python ou bash d’interaction (prompt/response)

---

## 🔌 Étape 3 – MCP Server

- [ ] Démarrer serveur Flask/FastAPI
- [ ] Créer endpoint `GET /tools` → retourne la liste des outils disponibles
- [ ] Créer endpoint `POST /run` → exécute l’action demandée
- [ ] Implémenter outils initiaux :
  - [ ] `get_time`
  - [ ] `read_note`
  - [ ] `run_script`

---

## 🔁 Étape 4 – Pont IA ↔ MCP

- [ ] Analyser réponse de l’IA pour identifier une intention/action
- [ ] Si action → POST vers le MCP avec les bons paramètres
- [ ] Retourner résultat à l’utilisateur

---

## 🪢 Étape 5 – Workflows `n8n`

- [ ] Installer et lancer serveur `n8n`
- [ ] Créer un premier workflow déclenché par webhook
- [ ] Ajouter un outil MCP `trigger_n8n_workflow`

---

## 🎙️ Étape 6 – Option voix

- [ ] Ajouter `whisper.cpp` (entrée vocale → texte)
- [ ] Ajouter `pyttsx3` ou autre TTS (texte → voix)
- [ ] Intégrer voix au cycle complet (prompt audio → réponse parlée)

---

## ✅ Finalisation

- [ ] Tests de bout en bout (prompt vocal → action déclenchée)
- [ ] Débug, journaux, logs intelligibles
- [ ] Écriture de la documentation utilisateur
- [ ] Créer un petit script de démonstration

---

📌 _Ceci est un plan souple. Il pourra être mis à jour selon les priorités ou les explorations IA futures._
