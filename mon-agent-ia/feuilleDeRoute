
---

# ğŸ—ºï¸ `roadmap.md` â€” *Feuille de route de progression*

```markdown
# ğŸ“ Feuille de Route â€“ Agent IA Local

DerniÃ¨re mise Ã  jour : [DATE]

## ğŸ¯ Objectif global

Construire un assistant IA local autonome, modulaire, vocal (optionnel), interconnectÃ© Ã  des outils personnalisÃ©s.

---

## âœ… Ã‰tape 1 â€“ Setup initial

- [x] GÃ©nÃ©rer lâ€™arborescence du projet via `init.sh`
- [x] Remplir `config.json` (chemins, ports, options vocales)

---

## ğŸ§  Ã‰tape 2 â€“ IA locale avec llama.cpp

- [ ] TÃ©lÃ©charger modÃ¨le `.gguf` (TinyLlama ou Phi)
- [ ] Lancer modÃ¨le en local (`./main`)
- [ ] Ã‰crire un script Python ou bash dâ€™interaction (prompt/response)

---

## ğŸ”Œ Ã‰tape 3 â€“ MCP Server

- [ ] DÃ©marrer serveur Flask/FastAPI
- [ ] CrÃ©er endpoint `GET /tools` â†’ retourne la liste des outils disponibles
- [ ] CrÃ©er endpoint `POST /run` â†’ exÃ©cute lâ€™action demandÃ©e
- [ ] ImplÃ©menter outils initiaux :
  - [ ] `get_time`
  - [ ] `read_note`
  - [ ] `run_script`

---

## ğŸ” Ã‰tape 4 â€“ Pont IA â†” MCP

- [ ] Analyser rÃ©ponse de lâ€™IA pour identifier une intention/action
- [ ] Si action â†’ POST vers le MCP avec les bons paramÃ¨tres
- [ ] Retourner rÃ©sultat Ã  lâ€™utilisateur

---

## ğŸª¢ Ã‰tape 5 â€“ Workflows `n8n`

- [ ] Installer et lancer serveur `n8n`
- [ ] CrÃ©er un premier workflow dÃ©clenchÃ© par webhook
- [ ] Ajouter un outil MCP `trigger_n8n_workflow`

---

## ğŸ™ï¸ Ã‰tape 6 â€“ Option voix

- [ ] Ajouter `whisper.cpp` (entrÃ©e vocale â†’ texte)
- [ ] Ajouter `pyttsx3` ou autre TTS (texte â†’ voix)
- [ ] IntÃ©grer voix au cycle complet (prompt audio â†’ rÃ©ponse parlÃ©e)

---

## âœ… Finalisation

- [ ] Tests de bout en bout (prompt vocal â†’ action dÃ©clenchÃ©e)
- [ ] DÃ©bug, journaux, logs intelligibles
- [ ] Ã‰criture de la documentation utilisateur
- [ ] CrÃ©er un petit script de dÃ©monstration

---

ğŸ“Œ _Ceci est un plan souple. Il pourra Ãªtre mis Ã  jour selon les prioritÃ©s ou les explorations IA futures._
